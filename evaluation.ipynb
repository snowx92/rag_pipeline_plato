{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e20ddbb",
   "metadata": {},
   "source": [
    "## imports & pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c7c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Notebook setup: adjust as needed for your repo layout ---\n",
    "import os, sys, json, hashlib, textwrap, time\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()  # change if running from a subdir\n",
    "SRC = PROJECT_ROOT / \"src\"\n",
    "\n",
    "# Ensure we can import project modules (schema, pipeline, etc.)\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "# Optional: silence Chroma's \"k>docs\" info messages\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "# Helpers\n",
    "def stable_json(obj) -> str:\n",
    "    \"\"\"Deterministic JSON string (sorted keys, no whitespace ambiguity).\"\"\"\n",
    "    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "def sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def print_ok(label: str):\n",
    "    print(f\"✅ {label}\")\n",
    "\n",
    "def print_skip(label: str, reason: str):\n",
    "    print(f\"⏭️  Skipped {label}: {reason}\")\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Optionally, also silence specific noisy libraries\n",
    "logging.getLogger('chromadb').setLevel(logging.ERROR)\n",
    "logging.getLogger('openai').setLevel(logging.ERROR)\n",
    "logging.getLogger('urllib3').setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbde8d3",
   "metadata": {},
   "source": [
    "## JD + resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5ca386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal JD & resume fixtures used in tests\n",
    "JD_SIMPLE = {\n",
    "    \"title\": \"Program Manager\",\n",
    "    \"sector\": \"Operations & Supply Chain\",\n",
    "    \"location\": \"Hybrid – Cairo\",\n",
    "    \"description\": \"We are hiring a Program Manager in Operations & Supply Chain to drive outcomes.\",\n",
    "    \"requirements\": [\n",
    "        \"1+ years of relevant experience\",\n",
    "        \"Bachelor's degree or equivalent experience\",\n",
    "        \"Proficiency in Lean\",\n",
    "        \"Proficiency in Six Sigma\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "RESUME_SIMPLE = textwrap.dedent(\"\"\"\n",
    "    Delivered 5 projects using Project Planning, SAP, Lean with measurable KPIs.\n",
    "    Collaborated with 7 stakeholders to ship on schedule. Six Sigma exposure.\n",
    "\"\"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104413e4",
   "metadata": {},
   "source": [
    "### Rules-only determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e81285a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules mode overallScore across runs: [76, 76, 76, 76, 76, 76, 76, 76, 76, 76]\n",
      "✅ Rules-only determinism: 10 runs produced identical outputs (hash=4bf087f2610ba77e5715182d72099d120efe0e08b6c5e78a006a8ee489c6a9dc)\n"
     ]
    }
   ],
   "source": [
    "from parse_resume import parse_resume\n",
    "from retrieve import build_resume_collection, retrieve_for_requirements\n",
    "from scorer import score_rule_based\n",
    "from schema import validate_json\n",
    "from uuid import uuid4\n",
    "\n",
    "def run_rules_once(jd: dict, resume_text: str, k: int = 3) -> dict:\n",
    "    parsed = parse_resume(resume_text, jd.get(\"requirements\", []))\n",
    "    lines = parsed.get(\"evidence_lines\", [])\n",
    "    if len(lines) < 2:\n",
    "        lines = [ln.strip() for ln in resume_text.splitlines() if ln.strip()]\n",
    "    # Unique collection to avoid clashes; name doesn't affect scoring\n",
    "    name = f\"resume_v0_{uuid4().hex[:8]}\"\n",
    "    _, coll = build_resume_collection(lines, collection_name=name)\n",
    "    reqs = [r for r in jd.get(\"requirements\", []) if r.lower().startswith(\"proficiency in \")]\n",
    "    hits = retrieve_for_requirements(coll, reqs, k=k)\n",
    "    out = score_rule_based(jd, parsed, hits)\n",
    "    ok, errs = validate_json(out)\n",
    "    assert ok, f\"Schema invalid: {errs}\"\n",
    "    return out\n",
    "\n",
    "# Run the rules path multiple times and verify identical outputs\n",
    "N = 10\n",
    "outputs = []\n",
    "hashes = []\n",
    "overall_scores = []\n",
    "\n",
    "for i in range(N):\n",
    "    out = run_rules_once(JD_SIMPLE, RESUME_SIMPLE, k=3)\n",
    "    s = stable_json(out)\n",
    "    outputs.append(out)\n",
    "    hashes.append(sha256_text(s))\n",
    "    overall_scores.append(out[\"overallScore\"])\n",
    "\n",
    "print(\"Rules mode overallScore across runs:\", overall_scores)\n",
    "\n",
    "# Determinism check (byte-identical)\n",
    "assert len(set(hashes)) == 1, \"Rules mode outputs differ across runs!\"\n",
    "print_ok(f\"Rules-only determinism: {N} runs produced identical outputs (hash={hashes[0]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afc872",
   "metadata": {},
   "source": [
    "### LLM determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8402e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[llm] chat.completions.create(...) called\n",
      "[llm] chat.completions.create(...) called\n",
      "[llm] chat.completions.create(...) called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM mode overallScore across runs: [76, 76, 76]\n",
      "✅ LLM determinism: 3 runs produced identical outputs (hash=4bf087f2610ba77e5715182d72099d120efe0e08b6c5e78a006a8ee489c6a9dc) using model=gpt-4o-mini-2024-08-06, seed=42, temp=0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pipeline import run_pipeline, PipelineConfig\n",
    "from schema import validate_json\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def run_llm_once(jd: dict, resume_text: str, k: int = 3, model: str = \"gpt-4o-mini-2024-08-06\", seed: int = 42) -> dict:\n",
    "    cfg = PipelineConfig(k=k, model=model, seed=seed)\n",
    "    out = run_pipeline(jd, resume_text, cfg=cfg)  # has schema check & LLM repair+fallback inside\n",
    "    ok, errs = validate_json(out)\n",
    "    assert ok, f\"Schema invalid: {errs}\"\n",
    "    return out\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print_skip(\"LLM determinism\", \"OPENAI_API_KEY is not set; cannot call the model.\")\n",
    "else:\n",
    "    # If your account lacks the default model, change it here to an available one.\n",
    "    MODEL = \"gpt-4o-mini-2024-08-06\"\n",
    "\n",
    "    M = 3\n",
    "    outs_llm = []\n",
    "    hashes_llm = []\n",
    "    llm_overall_scores = []\n",
    "\n",
    "    for _ in range(M):\n",
    "        out = run_llm_once(JD_SIMPLE, RESUME_SIMPLE, k=3, model=MODEL, seed=42)\n",
    "        s = stable_json(out)\n",
    "        outs_llm.append(out)\n",
    "        hashes_llm.append(sha256_text(s))\n",
    "        llm_overall_scores.append(out[\"overallScore\"])\n",
    "\n",
    "    print(\"LLM mode overallScore across runs:\", llm_overall_scores)\n",
    "\n",
    "    assert len(set(hashes_llm)) == 1, \"LLM mode outputs differ across runs! Check temperature/seed/model.\"\n",
    "    print_ok(f\"LLM determinism: {M} runs produced identical outputs (hash={hashes_llm[0]}) using model={MODEL}, seed=42, temp=0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07273112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
